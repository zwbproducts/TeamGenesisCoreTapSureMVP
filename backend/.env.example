# Optional: legacy OpenAI key (not required when using Ollama or other OAI-compatible backends)
OPENAI_API_KEY=
# OpenAI-compatible endpoint (e.g., Ollama). Example: http://localhost:11434/v1
LLM_BASE_URL=
# API key for that endpoint (Ollama accepts any non-empty string, e.g., "ollama")
LLM_API_KEY=
# Model name (e.g., llama3.1:8b or llama3.2-vision:11b). For text-only parsing, any instruct model works.
LLM_MODEL=llama3.1:8b
# Optional path to tesseract.exe on Windows, if not on PATH
TESSERACT_CMD=
FRONTEND_ORIGIN=http://localhost:5173
